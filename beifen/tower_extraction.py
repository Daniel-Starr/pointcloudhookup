# å‚ç…§towers.pyæ›´æ–°çš„tower_extraction.py

import laspy
import numpy as np
import trimesh
from sklearn.cluster import DBSCAN
from pathlib import Path
import gc
import time
import math
import pandas as pd
import open3d as o3d
import os
import warnings

# é…ç½®ç¯å¢ƒ
warnings.filterwarnings("ignore", category=UserWarning, module="trimesh")


# ä¿®å¤é‡å¤ä¸‹é‡‡æ ·é—®é¢˜ - tower_extraction.py

def extract_towers(
        input_las_path,
        progress_callback=None,
        log_callback=None,
        # å‚æ•°ä¿æŒä¸å˜
        eps=8.0,
        min_points=80,
        aspect_ratio_threshold=0.8,
        min_height=15.0,
        max_width=50.0,
        min_width=8,
        duplicate_threshold=25.0,
        # æ–°å¢å‚æ•°æ§åˆ¶æ˜¯å¦ä¸‹é‡‡æ ·
        skip_downsampling=True,  # è·³è¿‡ä¸‹é‡‡æ ·ï¼ˆä¸»ç•Œé¢å·²ä¸‹é‡‡æ ·ï¼‰
        max_points_for_processing=500000
):
    """
    ä¿®å¤é‡å¤ä¸‹é‡‡æ ·çš„æ†å¡”æå–ç®—æ³•
    - å¦‚æœä¸»ç•Œé¢å·²ç»ä¸‹é‡‡æ ·ï¼Œè®¾ç½®skip_downsampling=True
    - å¦‚æœç›´æ¥æµ‹è¯•åŸå§‹æ–‡ä»¶ï¼Œè®¾ç½®skip_downsampling=False
    """

    tower_obbs = []
    tower_info_list = []

    def log(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)

    def progress(value):
        if progress_callback:
            progress_callback(value)

    output_dir = Path("output_towers")
    output_dir.mkdir(exist_ok=True)

    # ==================== æ™ºèƒ½æ•°æ®è¯»å– ====================
    try:
        log("ğŸ“‚ è¯»å–ç‚¹äº‘æ–‡ä»¶...")
        progress(5)

        with laspy.open(input_las_path) as las_file:
            header = las_file.header
            total_points = header.point_count

            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼Œåˆ¤æ–­æ˜¯å¦å·²ç»ä¸‹é‡‡æ ·
            is_downsampled_file = ("point_2.las" in input_las_path or
                                   "output" in input_las_path or
                                   skip_downsampling)

            if is_downsampled_file:
                log(f"ğŸ” æ£€æµ‹åˆ°å·²ä¸‹é‡‡æ ·æ–‡ä»¶: {total_points:,} ä¸ªç‚¹")
                log("âš¡ è·³è¿‡ä¸‹é‡‡æ ·æ­¥éª¤ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰æ•°æ®")

                # ç›´æ¥è¯»å–å…¨éƒ¨æ•°æ®
                las = las_file.read()
                raw_points = np.stack([las.x, las.y, las.z], axis=1).astype(np.float32)

            else:
                log(f"ğŸ“Š æ£€æµ‹åˆ°åŸå§‹æ–‡ä»¶: {total_points:,} ä¸ªç‚¹")

                # åªæœ‰åŸå§‹æ–‡ä»¶æ‰è¿›è¡Œä¸‹é‡‡æ ·
                if total_points > max_points_for_processing:
                    log(f"âš¡ æ‰§è¡Œä¸‹é‡‡æ ·: {total_points:,} â†’ {max_points_for_processing:,} ç‚¹")

                    las = las_file.read()
                    sample_ratio = max_points_for_processing / total_points
                    indices = np.random.choice(total_points, max_points_for_processing, replace=False)
                    raw_points = np.stack([las.x[indices], las.y[indices], las.z[indices]], axis=1).astype(np.float32)

                    log(f"âœ… ä¸‹é‡‡æ ·å®Œæˆ: {len(raw_points):,} ç‚¹")
                else:
                    las = las_file.read()
                    raw_points = np.stack([las.x, las.y, las.z], axis=1).astype(np.float32)
                    log(f"âœ… ç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®: {len(raw_points):,} ç‚¹")

            # è®¡ç®—è´¨å¿ƒå’Œç›¸å¯¹åæ ‡
            centroid = np.mean(raw_points, axis=0)
            points = raw_points - centroid

            header_info = {
                "scales": header.scales,
                "offsets": header.offsets,
                "point_format": header.point_format,
                "version": header.version,
                "centroid": centroid,
                "original_count": total_points,
                "processed_count": len(raw_points),
                "is_downsampled": is_downsampled_file
            }

            del las, raw_points
            gc.collect()

    except Exception as e:
        log(f"âš ï¸ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        return tower_obbs

    # ==================== é«˜åº¦è¿‡æ»¤ ====================
    try:
        log("ğŸ” æ‰§è¡Œé«˜åº¦è¿‡æ»¤...")
        progress(10)

        z_values = points[:, 2]
        base_height = np.percentile(z_values, 25)
        filtered_points = points[z_values > (base_height + 3.0)]

        filter_ratio = len(filtered_points) / len(points)
        log(f"âœ… é«˜åº¦è¿‡æ»¤: {len(points):,} â†’ {len(filtered_points):,} ç‚¹ (ä¿ç•™ç‡: {filter_ratio:.1%})")

        if len(filtered_points) < 1000:
            log("âš ï¸ è¿‡æ»¤åç‚¹æ•°å¤ªå°‘ï¼Œé™ä½è¿‡æ»¤é˜ˆå€¼")
            filtered_points = points[z_values > (base_height + 1.0)]
            log(f"ğŸ“ˆ è°ƒæ•´åç‚¹æ•°: {len(filtered_points):,}")

    except Exception as e:
        log(f"âš ï¸ é«˜åº¦è¿‡æ»¤å¤±è´¥: {str(e)}")
        return tower_obbs

    # ==================== åˆ†å—èšç±»å¤„ç† ====================
    chunk_size = 50000
    total_chunks = (len(filtered_points) + chunk_size - 1) // chunk_size

    log(f"\n=== åˆ†å—èšç±»ä¿¡æ¯ ===")
    log(f"ğŸ“¦ æ•°æ®æ¥æº: {'å·²ä¸‹é‡‡æ ·æ–‡ä»¶' if header_info['is_downsampled'] else 'åŸå§‹æ–‡ä»¶'}")
    log(f"ğŸ“Š å¤„ç†ç‚¹æ•°: {len(filtered_points):,}")
    log(f"ğŸ”¢ å—å¤§å°: {chunk_size:,}")
    log(f"ğŸ“‹ åˆ†å—æ•°: {total_chunks}")

    chunks = [filtered_points[i:i + chunk_size] for i in range(0, len(filtered_points), chunk_size)]
    all_labels = np.full(len(filtered_points), -1, dtype=np.int32)
    current_label = 0

    progress(20)

    for i, chunk in enumerate(chunks):
        try:
            chunk_progress = 20 + int(50 * i / len(chunks))
            log(f"ğŸ”„ å¤„ç†åˆ†å— {i + 1}/{len(chunks)} ({len(chunk):,}ç‚¹)")

            clustering = DBSCAN(
                eps=eps,
                min_samples=min_points,
                n_jobs=-1,
                algorithm='ball_tree'
            ).fit(chunk)

            chunk_labels = clustering.labels_
            valid_labels = chunk_labels[chunk_labels != -1]

            if len(valid_labels) > 0:
                chunk_labels[chunk_labels != -1] += current_label
                all_labels[i * chunk_size:min((i + 1) * chunk_size, len(filtered_points))] = chunk_labels
                current_label = np.max(chunk_labels) + 1
                log(f"   âœ… å‘ç° {len(set(valid_labels))} ä¸ªèšç±»")
            else:
                all_labels[i * chunk_size:min((i + 1) * chunk_size, len(filtered_points))] = chunk_labels
                log(f"   âŒ æœªå‘ç°æœ‰æ•ˆèšç±»")

            progress(chunk_progress)

        except Exception as e:
            log(f"âš ï¸ åˆ†å—{i + 1}èšç±»å¤±è´¥: {str(e)}")
        finally:
            del chunk, clustering, chunk_labels
            gc.collect()

    # ==================== æ†å¡”æ£€æµ‹ä¸å»é‡ ====================
    unique_labels = set(all_labels) - {-1}
    tower_centers = []

    log(f"\n=== æ†å¡”æ£€æµ‹ ===")
    log(f"ğŸ¯ å€™é€‰èšç±»æ•°é‡: {len(unique_labels)}")
    progress(75)

    valid_towers = 0
    for label_idx, label in enumerate(unique_labels):
        try:
            cluster_mask = (all_labels == label)
            cluster_points = filtered_points[cluster_mask]

            # è®¡ç®—OBB
            cluster_pc = trimesh.PointCloud(cluster_points)
            obb = cluster_pc.bounding_box_oriented
            extents = obb.extents

            # å‡ ä½•è¿‡æ»¤
            height = extents[2]
            width = max(extents[0], extents[1])
            aspect_ratio = height / width

            if not (height > min_height and min_width < width < max_width and aspect_ratio > aspect_ratio_threshold):
                continue

            # è®¡ç®—å…¨å±€åæ ‡
            obb_center = obb.transform[:3, 3] + header_info["centroid"]

            # å»é‡æ£€æŸ¥
            is_duplicate = False
            for existing in tower_centers:
                distance = np.linalg.norm(obb_center - existing)
                if distance < duplicate_threshold:
                    is_duplicate = True
                    break
            if is_duplicate:
                continue

            # è®¡ç®—åŒ—æ–¹å‘åè§’
            rotation_matrix = obb.transform[:3, :3]
            x_axis = rotation_matrix[:, 0]
            horizontal_direction = np.array([x_axis[0], x_axis[1], 0])
            if np.linalg.norm(horizontal_direction) > 1e-6:
                horizontal_direction /= np.linalg.norm(horizontal_direction)
            else:
                horizontal_direction = np.array([1, 0, 0])

            angle_rad = np.arctan2(horizontal_direction[1], horizontal_direction[0])
            north_angle = np.degrees(angle_rad)
            if north_angle < 0:
                north_angle += 360
            north_angle = (90 - north_angle) % 360

            # ä¿å­˜æ†å¡”ä¿¡æ¯
            tower_info = {
                "center": obb_center,
                "rotation": obb.transform[:3, :3],
                "extent": extents,
                "height": height,
                "width": width,
                "north_angle": north_angle,
                "points": cluster_points,
                "label": label
            }
            tower_obbs.append(tower_info)
            tower_centers.append(obb_center)

            tower_info_list.append({
                "ID": f"tower_{label}",
                "ç»åº¦": obb_center[0],
                "çº¬åº¦": obb_center[1],
                "æµ·æ‹”é«˜åº¦": obb_center[2],
                "æ†å¡”é«˜åº¦": height,
                "åŒ—æ–¹å‘åè§’": north_angle,
                "å®½åº¦": width,
                "é•¿å®½æ¯”": aspect_ratio,
                "ç‚¹æ•°": len(cluster_points)
            })

            # ä¿å­˜ç‚¹äº‘
            original_points = cluster_points + header_info["centroid"]
            output_path = output_dir / f"tower_{label}.las"
            _save_tower_las(original_points, None, header_info, output_path, log)

            valid_towers += 1
            log(f"âœ… æ†å¡”{valid_towers}: {height:.1f}mé«˜Ã—{width:.1f}må®½ (æ ‡ç­¾{label})")

            progress(75 + int(15 * (label_idx + 1) / len(unique_labels)))

        except Exception as e:
            log(f"âš ï¸ ç°‡{label} å¤„ç†å¤±è´¥: {str(e)}")
            continue
        finally:
            del cluster_points, cluster_pc, obb
            gc.collect()

    # ==================== ä¿å­˜ç»“æœ ====================
    if tower_info_list:
        try:
            output_excel_path = "towers_info.xlsx"
            df = pd.DataFrame(tower_info_list)
            df.to_excel(output_excel_path, index=False)

            log(f"\nğŸ“Š æ£€æµ‹å®Œæˆç»Ÿè®¡:")
            log(f"   æ•°æ®æ¥æº: {'å·²ä¸‹é‡‡æ ·' if header_info['is_downsampled'] else 'åŸå§‹æ–‡ä»¶'}")
            log(f"   å¤„ç†ç‚¹æ•°: {header_info['processed_count']:,}")
            log(f"   è¿‡æ»¤ç‚¹æ•°: {len(filtered_points):,}")
            log(f"   åˆ†å—æ•°é‡: {total_chunks}")
            log(f"   æœ‰æ•ˆæ†å¡”: {len(tower_obbs)}")
            log(f"âœ… ç»“æœå·²ä¿å­˜: {output_excel_path}")

        except Exception as e:
            log(f"âš ï¸ ä¿å­˜Excelå¤±è´¥: {str(e)}")
    else:
        log("\nâš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•æ†å¡”")

    progress(100)
    log("âœ… æ†å¡”æå–å®Œæˆ")
    return tower_obbs


# å…¶ä»–å‡½æ•°ä¿æŒä¸å˜
def _save_tower_las(points, colors, header_info, output_path, log_callback=None):
    """ä¿å­˜LASæ–‡ä»¶"""
    try:
        header = laspy.LasHeader(
            point_format=header_info["point_format"],
            version=header_info["version"]
        )
        header.scales = header_info["scales"]
        header.offsets = header_info["offsets"]

        las = laspy.LasData(header)
        las.x = points[:, 0].astype(np.float64)
        las.y = points[:, 1].astype(np.float64)
        las.z = points[:, 2].astype(np.float64)
        las.write(output_path)
        if log_callback:
            log_callback(f"ğŸ’¾ ä¿å­˜: {output_path.name}")
    except Exception as e:
        if log_callback:
            log_callback(f"âš ï¸ ä¿å­˜å¤±è´¥: {str(e)}")


def create_obb_geometries(tower_obbs):
    """åˆ›å»ºå‡ ä½•ä½“"""
    geometries = []
    for tower in tower_obbs:
        try:
            obb_o3d = o3d.geometry.OrientedBoundingBox()
            obb_o3d.center = tower['center']
            obb_o3d.extent = tower['extent']
            obb_o3d.R = tower['rotation']
            obb_mesh = o3d.geometry.LineSet.create_from_oriented_bounding_box(obb_o3d)
            obb_mesh.paint_uniform_color([1, 0, 0])
            geometries.append(obb_mesh)
        except Exception as e:
            continue
    return geometries

# ä¸ºäº†å…¼å®¹åŸæœ‰ä»£ç ï¼Œä¿ç•™å…¶ä»–å¯èƒ½éœ€è¦çš„å‡½æ•°
def extract_towers_optimized(*args, **kwargs):
    """å…¼å®¹æ€§å‡½æ•°"""
    return extract_towers(*args, **kwargs)


if __name__ == "__main__":
    """æµ‹è¯•å‡½æ•°"""
    start_time = time.time()
    try:
        extract_towers(
            input_las_path="E:/pointcloudhookup002/output/point_2.las",
            eps=8.0,  # æ ¹æ®åœºæ™¯è°ƒæ•´
            min_points=80,  # é€‚ç”¨äºå¯†é›†ç‚¹äº‘
            aspect_ratio_threshold=0.8,
            min_height=15.0,
            max_width=50.0,
            min_width=8
        )
    except Exception as e:
        print(f"âš ï¸ ç¨‹åºé”™è¯¯: {str(e)}")
    finally:
        print(f"\næ€»è¿è¡Œæ—¶é—´: {time.time() - start_time:.1f}ç§’")